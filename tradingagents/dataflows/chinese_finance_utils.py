#!/usr/bin/env python3
"""
ä¸­å›½è´¢ç»æ•°æ®èšåˆå·¥å…·
ç”±äºå¾®åšAPIç”³è¯·å›°éš¾ä¸”åŠŸèƒ½å—é™ï¼Œé‡‡ç”¨å¤šæºæ•°æ®èšåˆçš„æ–¹å¼
"""

import requests
import json
import time
import random
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import re
from bs4 import BeautifulSoup
import pandas as pd


class ChineseFinanceDataAggregator:
    """ä¸­å›½è´¢ç»æ•°æ®èšåˆå™¨"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def get_stock_sentiment_summary(self, ticker: str, days: int = 7) -> Dict:
        """
        è·å–è‚¡ç¥¨æƒ…ç»ªåˆ†ææ±‡æ€»
        æ•´åˆå¤šä¸ªå¯è·å–çš„ä¸­å›½è´¢ç»æ•°æ®æº
        """
        try:
            # 1. è·å–è´¢ç»æ–°é—»æƒ…ç»ª
            news_sentiment = self._get_finance_news_sentiment(ticker, days)
            
            # 2. è·å–è‚¡å§è®¨è®ºçƒ­åº¦ (å¦‚æœå¯ä»¥è·å–)
            forum_sentiment = self._get_stock_forum_sentiment(ticker, days)
            
            # 3. è·å–è´¢ç»åª’ä½“æŠ¥é“
            media_sentiment = self._get_media_coverage_sentiment(ticker, days)
            
            # 4. ç»¼åˆåˆ†æ
            overall_sentiment = self._calculate_overall_sentiment(
                news_sentiment, forum_sentiment, media_sentiment
            )
            
            return {
                'ticker': ticker,
                'analysis_period': f'{days} days',
                'overall_sentiment': overall_sentiment,
                'news_sentiment': news_sentiment,
                'forum_sentiment': forum_sentiment,
                'media_sentiment': media_sentiment,
                'summary': self._generate_sentiment_summary(overall_sentiment),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'ticker': ticker,
                'error': f'æ•°æ®è·å–å¤±è´¥: {str(e)}',
                'fallback_message': 'ç”±äºä¸­å›½ç¤¾äº¤åª’ä½“APIé™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨è´¢ç»æ–°é—»å’ŒåŸºæœ¬é¢åˆ†æä½œä¸ºä¸»è¦å‚è€ƒ',
                'timestamp': datetime.now().isoformat()
            }
    
    def _get_finance_news_sentiment(self, ticker: str, days: int) -> Dict:
        """è·å–è´¢ç»æ–°é—»æƒ…ç»ªåˆ†æ"""
        try:
            # æœç´¢ç›¸å…³æ–°é—»æ ‡é¢˜å’Œå†…å®¹
            company_name = self._get_company_chinese_name(ticker)
            search_terms = [ticker, company_name] if company_name else [ticker]
            
            news_items = []
            for term in search_terms:
                # è¿™é‡Œå¯ä»¥é›†æˆå¤šä¸ªæ–°é—»æº
                items = self._search_finance_news(term, days)
                news_items.extend(items)
            
            # ç®€å•çš„æƒ…ç»ªåˆ†æ
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            
            for item in news_items:
                sentiment = self._analyze_text_sentiment(item.get('title', '') + ' ' + item.get('content', ''))
                if sentiment > 0.1:
                    positive_count += 1
                elif sentiment < -0.1:
                    negative_count += 1
                else:
                    neutral_count += 1
            
            total = len(news_items)
            if total == 0:
                return {'sentiment_score': 0, 'confidence': 0, 'news_count': 0}
            
            sentiment_score = (positive_count - negative_count) / total
            
            return {
                'sentiment_score': sentiment_score,
                'positive_ratio': positive_count / total,
                'negative_ratio': negative_count / total,
                'neutral_ratio': neutral_count / total,
                'news_count': total,
                'confidence': min(total / 10, 1.0)  # æ–°é—»æ•°é‡è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜
            }
            
        except Exception as e:
            return {'error': str(e), 'sentiment_score': 0, 'confidence': 0}
    
    def _get_stock_forum_sentiment(self, ticker: str, days: int) -> Dict:
        """è·å–è‚¡ç¥¨è®ºå›è®¨è®ºæƒ…ç»ª (æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…éœ€è¦çˆ¬è™«)"""
        # ç”±äºä¸œæ–¹è´¢å¯Œè‚¡å§ç­‰å¹³å°çš„åçˆ¬è™«æœºåˆ¶ï¼Œè¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        # å®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„çˆ¬è™«æŠ€æœ¯
        
        return {
            'sentiment_score': 0,
            'discussion_count': 0,
            'hot_topics': [],
            'note': 'è‚¡ç¥¨è®ºå›æ•°æ®è·å–å—é™ï¼Œå»ºè®®å…³æ³¨å®˜æ–¹è´¢ç»æ–°é—»',
            'confidence': 0
        }
    
    def _get_media_coverage_sentiment(self, ticker: str, days: int) -> Dict:
        """è·å–åª’ä½“æŠ¥é“æƒ…ç»ª"""
        try:
            # å¯ä»¥é›†æˆRSSæºæˆ–å…¬å¼€çš„è´¢ç»API
            coverage_items = self._get_media_coverage(ticker, days)
            
            if not coverage_items:
                return {'sentiment_score': 0, 'coverage_count': 0, 'confidence': 0}
            
            # åˆ†æåª’ä½“æŠ¥é“çš„æƒ…ç»ªå€¾å‘
            sentiment_scores = []
            for item in coverage_items:
                score = self._analyze_text_sentiment(item.get('title', '') + ' ' + item.get('summary', ''))
                sentiment_scores.append(score)
            
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
            
            return {
                'sentiment_score': avg_sentiment,
                'coverage_count': len(coverage_items),
                'confidence': min(len(coverage_items) / 5, 1.0)
            }
            
        except Exception as e:
            return {'error': str(e), 'sentiment_score': 0, 'confidence': 0}
    
    def _search_finance_news(self, search_term: str, days: int) -> List[Dict]:
        """æœç´¢è´¢ç»æ–°é—» (ç¤ºä¾‹å®ç°)"""
        # è¿™é‡Œå¯ä»¥é›†æˆå¤šä¸ªæ–°é—»æºçš„APIæˆ–RSS
        # ä¾‹å¦‚ï¼šè´¢è”ç¤¾ã€æ–°æµªè´¢ç»ã€ä¸œæ–¹è´¢å¯Œç­‰
        
        # æ¨¡æ‹Ÿè¿”å›æ•°æ®ç»“æ„
        return [
            {
                'title': f'{search_term}ç›¸å…³è´¢ç»æ–°é—»æ ‡é¢˜',
                'content': 'æ–°é—»å†…å®¹æ‘˜è¦...',
                'source': 'è´¢è”ç¤¾',
                'publish_time': datetime.now().isoformat(),
                'url': 'https://example.com/news/1'
            }
        ]
    
    def _get_media_coverage(self, ticker: str, days: int) -> List[Dict]:
        """è·å–åª’ä½“æŠ¥é“ (ç¤ºä¾‹å®ç°)"""
        # å¯ä»¥é›†æˆGoogle News APIæˆ–å…¶ä»–æ–°é—»èšåˆæœåŠ¡
        return []
    
    def _analyze_text_sentiment(self, text: str) -> float:
        """ç®€å•çš„ä¸­æ–‡æ–‡æœ¬æƒ…ç»ªåˆ†æ"""
        if not text:
            return 0
        
        # ç®€å•çš„å…³é”®è¯æƒ…ç»ªåˆ†æ
        positive_words = ['ä¸Šæ¶¨', 'å¢é•¿', 'åˆ©å¥½', 'çœ‹å¥½', 'ä¹°å…¥', 'æ¨è', 'å¼ºåŠ¿', 'çªç ´', 'åˆ›æ–°é«˜']
        negative_words = ['ä¸‹è·Œ', 'ä¸‹é™', 'åˆ©ç©º', 'çœ‹ç©º', 'å–å‡º', 'é£é™©', 'è·Œç ´', 'åˆ›æ–°ä½', 'äºæŸ']
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count + negative_count == 0:
            return 0
        
        return (positive_count - negative_count) / (positive_count + negative_count)
    
    def _get_company_chinese_name(self, ticker: str) -> Optional[str]:
        """è·å–å…¬å¸ä¸­æ–‡åç§°"""
        # ç®€å•çš„æ˜ å°„è¡¨ï¼Œå®é™…å¯ä»¥ä»æ•°æ®åº“æˆ–APIè·å–
        name_mapping = {
            'AAPL': 'è‹¹æœ',
            'TSLA': 'ç‰¹æ–¯æ‹‰',
            'NVDA': 'è‹±ä¼Ÿè¾¾',
            'MSFT': 'å¾®è½¯',
            'GOOGL': 'è°·æ­Œ',
            'AMZN': 'äºšé©¬é€Š'
        }
        return name_mapping.get(ticker.upper())
    
    def _calculate_overall_sentiment(self, news_sentiment: Dict, forum_sentiment: Dict, media_sentiment: Dict) -> Dict:
        """è®¡ç®—ç»¼åˆæƒ…ç»ªåˆ†æ"""
        # æ ¹æ®å„æ•°æ®æºçš„ç½®ä¿¡åº¦åŠ æƒè®¡ç®—
        news_weight = news_sentiment.get('confidence', 0)
        forum_weight = forum_sentiment.get('confidence', 0)
        media_weight = media_sentiment.get('confidence', 0)
        
        total_weight = news_weight + forum_weight + media_weight
        
        if total_weight == 0:
            return {'sentiment_score': 0, 'confidence': 0, 'level': 'neutral'}
        
        weighted_sentiment = (
            news_sentiment.get('sentiment_score', 0) * news_weight +
            forum_sentiment.get('sentiment_score', 0) * forum_weight +
            media_sentiment.get('sentiment_score', 0) * media_weight
        ) / total_weight
        
        # ç¡®å®šæƒ…ç»ªç­‰çº§
        if weighted_sentiment > 0.3:
            level = 'very_positive'
        elif weighted_sentiment > 0.1:
            level = 'positive'
        elif weighted_sentiment > -0.1:
            level = 'neutral'
        elif weighted_sentiment > -0.3:
            level = 'negative'
        else:
            level = 'very_negative'
        
        return {
            'sentiment_score': weighted_sentiment,
            'confidence': total_weight / 3,  # å¹³å‡ç½®ä¿¡åº¦
            'level': level
        }
    
    def _generate_sentiment_summary(self, overall_sentiment: Dict) -> str:
        """ç”Ÿæˆæƒ…ç»ªåˆ†ææ‘˜è¦"""
        level = overall_sentiment.get('level', 'neutral')
        score = overall_sentiment.get('sentiment_score', 0)
        confidence = overall_sentiment.get('confidence', 0)
        
        level_descriptions = {
            'very_positive': 'éå¸¸ç§¯æ',
            'positive': 'ç§¯æ',
            'neutral': 'ä¸­æ€§',
            'negative': 'æ¶ˆæ',
            'very_negative': 'éå¸¸æ¶ˆæ'
        }
        
        description = level_descriptions.get(level, 'ä¸­æ€§')
        confidence_level = 'é«˜' if confidence > 0.7 else 'ä¸­' if confidence > 0.3 else 'ä½'
        
        return f"å¸‚åœºæƒ…ç»ª: {description} (è¯„åˆ†: {score:.2f}, ç½®ä¿¡åº¦: {confidence_level})"


def get_chinese_social_sentiment(ticker: str, curr_date: str) -> str:
    """
    è·å–ä¸­å›½ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æçš„ä¸»è¦æ¥å£å‡½æ•°
    """
    aggregator = ChineseFinanceDataAggregator()
    
    try:
        # è·å–æƒ…ç»ªåˆ†ææ•°æ®
        sentiment_data = aggregator.get_stock_sentiment_summary(ticker, days=7)
        
        # æ ¼å¼åŒ–è¾“å‡º
        if 'error' in sentiment_data:
            return f"""
ä¸­å›½å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š - {ticker}
åˆ†ææ—¥æœŸ: {curr_date}

âš ï¸ æ•°æ®è·å–é™åˆ¶è¯´æ˜:
{sentiment_data.get('fallback_message', 'æ•°æ®è·å–é‡åˆ°æŠ€æœ¯é™åˆ¶')}

å»ºè®®:
1. é‡ç‚¹å…³æ³¨è´¢ç»æ–°é—»å’ŒåŸºæœ¬é¢åˆ†æ
2. å‚è€ƒå®˜æ–¹è´¢æŠ¥å’Œä¸šç»©æŒ‡å¯¼
3. å…³æ³¨è¡Œä¸šæ”¿ç­–å’Œç›‘ç®¡åŠ¨æ€
4. è€ƒè™‘å›½é™…å¸‚åœºæƒ…ç»ªå¯¹ä¸­æ¦‚è‚¡çš„å½±å“

æ³¨: ç”±äºä¸­å›½ç¤¾äº¤åª’ä½“å¹³å°APIé™åˆ¶ï¼Œå½“å‰ä¸»è¦ä¾èµ–å…¬å¼€è´¢ç»æ•°æ®æºè¿›è¡Œåˆ†æã€‚
"""
        
        overall = sentiment_data.get('overall_sentiment', {})
        news = sentiment_data.get('news_sentiment', {})
        
        return f"""
ä¸­å›½å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š - {ticker}
åˆ†ææ—¥æœŸ: {curr_date}
åˆ†æå‘¨æœŸ: {sentiment_data.get('analysis_period', '7å¤©')}

ğŸ“Š ç»¼åˆæƒ…ç»ªè¯„ä¼°:
{sentiment_data.get('summary', 'æ•°æ®ä¸è¶³')}

ğŸ“° è´¢ç»æ–°é—»æƒ…ç»ª:
- æƒ…ç»ªè¯„åˆ†: {news.get('sentiment_score', 0):.2f}
- æ­£é¢æ–°é—»æ¯”ä¾‹: {news.get('positive_ratio', 0):.1%}
- è´Ÿé¢æ–°é—»æ¯”ä¾‹: {news.get('negative_ratio', 0):.1%}
- æ–°é—»æ•°é‡: {news.get('news_count', 0)}æ¡

ğŸ’¡ æŠ•èµ„å»ºè®®:
åŸºäºå½“å‰å¯è·å–çš„ä¸­å›½å¸‚åœºæ•°æ®ï¼Œå»ºè®®æŠ•èµ„è€…:
1. å¯†åˆ‡å…³æ³¨å®˜æ–¹è´¢ç»åª’ä½“æŠ¥é“
2. é‡è§†åŸºæœ¬é¢åˆ†æå’Œè´¢åŠ¡æ•°æ®
3. è€ƒè™‘æ”¿ç­–ç¯å¢ƒå¯¹è‚¡ä»·çš„å½±å“
4. å…³æ³¨å›½é™…å¸‚åœºåŠ¨æ€

âš ï¸ æ•°æ®è¯´æ˜:
ç”±äºä¸­å›½ç¤¾äº¤åª’ä½“å¹³å°APIè·å–é™åˆ¶ï¼Œæœ¬åˆ†æä¸»è¦åŸºäºå…¬å¼€è´¢ç»æ–°é—»æ•°æ®ã€‚
å»ºè®®ç»“åˆå…¶ä»–åˆ†æç»´åº¦è¿›è¡Œç»¼åˆåˆ¤æ–­ã€‚

ç”Ÿæˆæ—¶é—´: {sentiment_data.get('timestamp', datetime.now().isoformat())}
"""
        
    except Exception as e:
        return f"""
ä¸­å›½å¸‚åœºæƒ…ç»ªåˆ†æ - {ticker}
åˆ†ææ—¥æœŸ: {curr_date}

âŒ åˆ†æå¤±è´¥: {str(e)}

ğŸ’¡ æ›¿ä»£å»ºè®®:
1. æŸ¥çœ‹è´¢ç»æ–°é—»ç½‘ç«™çš„ç›¸å…³æŠ¥é“
2. å…³æ³¨é›ªçƒã€ä¸œæ–¹è´¢å¯Œç­‰æŠ•èµ„ç¤¾åŒºè®¨è®º
3. å‚è€ƒä¸“ä¸šæœºæ„çš„ç ”ç©¶æŠ¥å‘Š
4. é‡ç‚¹åˆ†æåŸºæœ¬é¢å’ŒæŠ€æœ¯é¢æ•°æ®

æ³¨: ä¸­å›½ç¤¾äº¤åª’ä½“æ•°æ®è·å–å­˜åœ¨æŠ€æœ¯é™åˆ¶ï¼Œå»ºè®®ä»¥åŸºæœ¬é¢åˆ†æä¸ºä¸»ã€‚
"""
