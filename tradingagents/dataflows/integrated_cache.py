#!/usr/bin/env python3
"""
é›†æˆç¼“å­˜ç®¡ç†å™¨
ç»“åˆåŸæœ‰ç¼“å­˜ç³»ç»Ÿå’Œæ–°çš„è‡ªé€‚åº”æ•°æ®åº“æ”¯æŒ
æä¾›å‘åå…¼å®¹çš„æ¥å£
"""

import os
import logging
from pathlib import Path
from typing import Any, Dict, Optional, Union
import pandas as pd

# å¯¼å…¥åŸæœ‰ç¼“å­˜ç³»ç»Ÿ
from .cache_manager import StockDataCache

# å¯¼å…¥è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿ
try:
    from .adaptive_cache import get_cache_system
    from ..config.database_manager import get_database_manager
    ADAPTIVE_CACHE_AVAILABLE = True
except ImportError:
    ADAPTIVE_CACHE_AVAILABLE = False

class IntegratedCacheManager:
    """é›†æˆç¼“å­˜ç®¡ç†å™¨ - æ™ºèƒ½é€‰æ‹©ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self, cache_dir: str = None):
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–åŸæœ‰ç¼“å­˜ç³»ç»Ÿï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
        self.legacy_cache = StockDataCache(cache_dir)
        
        # å°è¯•åˆå§‹åŒ–è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿ
        self.adaptive_cache = None
        self.use_adaptive = False
        
        if ADAPTIVE_CACHE_AVAILABLE:
            try:
                self.adaptive_cache = get_cache_system()
                self.db_manager = get_database_manager()
                self.use_adaptive = True
                self.logger.info("âœ… è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨")
            except Exception as e:
                self.logger.warning(f"è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿç¼“å­˜: {e}")
                self.use_adaptive = False
        else:
            self.logger.info("è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–‡ä»¶ç¼“å­˜")
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        self._log_cache_status()
    
    def _log_cache_status(self):
        """è®°å½•ç¼“å­˜çŠ¶æ€"""
        if self.use_adaptive:
            backend = self.adaptive_cache.primary_backend
            mongodb_available = self.db_manager.is_mongodb_available()
            redis_available = self.db_manager.is_redis_available()
            
            self.logger.info(f"ğŸ“Š ç¼“å­˜é…ç½®:")
            self.logger.info(f"  ä¸»è¦åç«¯: {backend}")
            self.logger.info(f"  MongoDB: {'âœ… å¯ç”¨' if mongodb_available else 'âŒ ä¸å¯ç”¨'}")
            self.logger.info(f"  Redis: {'âœ… å¯ç”¨' if redis_available else 'âŒ ä¸å¯ç”¨'}")
            self.logger.info(f"  é™çº§æ”¯æŒ: {'âœ… å¯ç”¨' if self.adaptive_cache.fallback_enabled else 'âŒ ç¦ç”¨'}")
        else:
            self.logger.info("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ–‡ä»¶ç¼“å­˜ç³»ç»Ÿ")
    
    def save_stock_data(self, symbol: str, data: Any, start_date: str = None, 
                       end_date: str = None, data_source: str = "default") -> str:
        """
        ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°ç¼“å­˜
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: è‚¡ç¥¨æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            data_source: æ•°æ®æº
            
        Returns:
            ç¼“å­˜é”®
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿ
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                start_date=start_date or "",
                end_date=end_date or "",
                data_source=data_source,
                data_type="stock_data"
            )
        else:
            # ä½¿ç”¨ä¼ ç»Ÿç¼“å­˜ç³»ç»Ÿ
            return self.legacy_cache.save_stock_data(
                symbol=symbol,
                data=data,
                start_date=start_date,
                end_date=end_date,
                data_source=data_source
            )
    
    def load_stock_data(self, cache_key: str) -> Optional[Any]:
        """
        ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            cache_key: ç¼“å­˜é”®
            
        Returns:
            è‚¡ç¥¨æ•°æ®æˆ–None
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿ
            return self.adaptive_cache.load_data(cache_key)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿç¼“å­˜ç³»ç»Ÿ
            return self.legacy_cache.load_stock_data(cache_key)
    
    def find_cached_stock_data(self, symbol: str, start_date: str = None, 
                              end_date: str = None, data_source: str = "default") -> Optional[str]:
        """
        æŸ¥æ‰¾ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            data_source: æ•°æ®æº
            
        Returns:
            ç¼“å­˜é”®æˆ–None
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé€‚åº”ç¼“å­˜ç³»ç»Ÿ
            return self.adaptive_cache.find_cached_data(
                symbol=symbol,
                start_date=start_date or "",
                end_date=end_date or "",
                data_source=data_source,
                data_type="stock_data"
            )
        else:
            # ä½¿ç”¨ä¼ ç»Ÿç¼“å­˜ç³»ç»Ÿ
            return self.legacy_cache.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                data_source=data_source
            )
    
    def save_news_data(self, symbol: str, data: Any, data_source: str = "default") -> str:
        """ä¿å­˜æ–°é—»æ•°æ®"""
        if self.use_adaptive:
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                data_source=data_source,
                data_type="news_data"
            )
        else:
            return self.legacy_cache.save_news_data(symbol, data, data_source)
    
    def load_news_data(self, cache_key: str) -> Optional[Any]:
        """åŠ è½½æ–°é—»æ•°æ®"""
        if self.use_adaptive:
            return self.adaptive_cache.load_data(cache_key)
        else:
            return self.legacy_cache.load_news_data(cache_key)
    
    def save_fundamentals_data(self, symbol: str, data: Any, data_source: str = "default") -> str:
        """ä¿å­˜åŸºæœ¬é¢æ•°æ®"""
        if self.use_adaptive:
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                data_source=data_source,
                data_type="fundamentals_data"
            )
        else:
            return self.legacy_cache.save_fundamentals_data(symbol, data, data_source)
    
    def load_fundamentals_data(self, cache_key: str) -> Optional[Any]:
        """åŠ è½½åŸºæœ¬é¢æ•°æ®"""
        if self.use_adaptive:
            return self.adaptive_cache.load_data(cache_key)
        else:
            return self.legacy_cache.load_fundamentals_data(cache_key)
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self.use_adaptive:
            # è·å–è‡ªé€‚åº”ç¼“å­˜ç»Ÿè®¡
            adaptive_stats = self.adaptive_cache.get_cache_stats()
            
            # æ·»åŠ ä¼ ç»Ÿç¼“å­˜ç»Ÿè®¡
            legacy_stats = self.legacy_cache.get_cache_stats()
            
            return {
                "cache_system": "adaptive",
                "adaptive_cache": adaptive_stats,
                "legacy_cache": legacy_stats,
                "database_available": self.db_manager.is_database_available(),
                "mongodb_available": self.db_manager.is_mongodb_available(),
                "redis_available": self.db_manager.is_redis_available()
            }
        else:
            # åªè¿”å›ä¼ ç»Ÿç¼“å­˜ç»Ÿè®¡
            legacy_stats = self.legacy_cache.get_cache_stats()
            return {
                "cache_system": "legacy",
                "legacy_cache": legacy_stats,
                "database_available": False,
                "mongodb_available": False,
                "redis_available": False
            }
    
    def clear_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        if self.use_adaptive:
            self.adaptive_cache.clear_expired_cache()
        
        # æ€»æ˜¯æ¸…ç†ä¼ ç»Ÿç¼“å­˜
        self.legacy_cache.clear_expired_cache()
    
    def get_cache_backend_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜åç«¯ä¿¡æ¯"""
        if self.use_adaptive:
            return {
                "system": "adaptive",
                "primary_backend": self.adaptive_cache.primary_backend,
                "fallback_enabled": self.adaptive_cache.fallback_enabled,
                "mongodb_available": self.db_manager.is_mongodb_available(),
                "redis_available": self.db_manager.is_redis_available()
            }
        else:
            return {
                "system": "legacy",
                "primary_backend": "file",
                "fallback_enabled": False,
                "mongodb_available": False,
                "redis_available": False
            }
    
    def is_database_available(self) -> bool:
        """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å¯ç”¨"""
        if self.use_adaptive:
            return self.db_manager.is_database_available()
        return False
    
    def get_performance_mode(self) -> str:
        """è·å–æ€§èƒ½æ¨¡å¼"""
        if not self.use_adaptive:
            return "åŸºç¡€æ¨¡å¼ (æ–‡ä»¶ç¼“å­˜)"
        
        mongodb_available = self.db_manager.is_mongodb_available()
        redis_available = self.db_manager.is_redis_available()
        
        if redis_available and mongodb_available:
            return "é«˜æ€§èƒ½æ¨¡å¼ (Redis + MongoDB + æ–‡ä»¶)"
        elif redis_available:
            return "å¿«é€Ÿæ¨¡å¼ (Redis + æ–‡ä»¶)"
        elif mongodb_available:
            return "æŒä¹…åŒ–æ¨¡å¼ (MongoDB + æ–‡ä»¶)"
        else:
            return "æ ‡å‡†æ¨¡å¼ (æ™ºèƒ½æ–‡ä»¶ç¼“å­˜)"


# å…¨å±€é›†æˆç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_integrated_cache = None

def get_cache() -> IntegratedCacheManager:
    """è·å–å…¨å±€é›†æˆç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _integrated_cache
    if _integrated_cache is None:
        _integrated_cache = IntegratedCacheManager()
    return _integrated_cache

# å‘åå…¼å®¹çš„å‡½æ•°
def get_stock_cache():
    """å‘åå…¼å®¹ï¼šè·å–è‚¡ç¥¨ç¼“å­˜"""
    return get_cache()

def create_cache_manager(cache_dir: str = None):
    """å‘åå…¼å®¹ï¼šåˆ›å»ºç¼“å­˜ç®¡ç†å™¨"""
    return IntegratedCacheManager(cache_dir)
